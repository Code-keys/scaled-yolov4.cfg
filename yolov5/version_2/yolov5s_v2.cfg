[net]
# Testing
#batch=1
#subdivisions=1
# Training

batch=64
subdivisions=16
width=640
height=640
channels=3
momentum=0.949
decay=0.0005
angle=0.3
saturation = 1.5
exposure = 1.5
hue=.1

# learning_rate=0.00261
learning_rate=0.001
decay=0.0005
burn_in=1000
max_batches =30000
policy=steps
steps=15000,25000
scales=.1,.1

#cutmix=1
mosaic=1

#:104x104 54:52x52 85:26x26 104:13x13 for 416
# Focus
[convolutional]
batch_normalize=1
filters=12
size=3
stride=2
pad=1
activation=linear
groups=3
# xnor=1
# bin_output=1

# maybe useful ( mix up ) 
[convolutional]
batch_normalize=1
filters=32
size=3
stride=2
pad=1
activation=leaky

# Downsample
# layer 10
[convolutional]
batch_normalize=1
filters=64
size=3
stride=2
pad=1
activation=leaky

# CSPBlock layer  11
[convolutional]
batch_normalize=0
filters=32
size=1
stride=1
pad=1
activation=linear

[route]
layers = -2
[convolutional]
batch_normalize=0
filters=32
size=1
stride=1
pad=1
activation=linear
# repeat  residual module  x1
[convolutional]
batch_normalize=1
filters=32
size=1
stride=1
pad=1
activation=leaky
[convolutional]
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=leaky
[shortcut]
from=-3
activation=linear
# repeat  residual module x1 end
[convolutional]
batch_normalize=0
filters=32
size=1
stride=1
pad=1
activation=leaky

[route]
layers = -1,-7
[batchnorm]
filters=64
[activation]
activation = leaky
[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky

# Downsample  layer  22
[convolutional]
batch_normalize=1
filters=128
size=3
stride=2
pad=1
activation=leaky

# CSPBlock  layer 23
[convolutional]
batch_normalize=0
filters=64
size=1
stride=1
pad=1
activation=linear

[route]
layers = -2
[convolutional]
batch_normalize=0
filters=64
size=1
stride=1
pad=1
activation=linear
# repeat  residual module x3
[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky
[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky
[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky
[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky
[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky
[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky
[shortcut]
from=-3
activation=linear

#  repeat  residual module x3 end layer :   layer 35
[convolutional]
batch_normalize=0
filters=64
size=1
stride=1
pad=1
activation=linear
# layer 36
[route]
layers = -1,-13

[batchnorm]
filters=128
[activation]
activation = leaky
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

# Downsample
# layer  41
[convolutional]
batch_normalize=1
filters=256
size=3
stride=2
pad=1
activation=leaky

# CSPBlock 
[convolutional]
batch_normalize=0
filters=128
size=1
stride=1
pad=1
activation=linear

[route]
layers = -2

[convolutional]
batch_normalize=0
filters=128
size=1
stride=1
pad=1
activation=linear

# repeat  resudual   layer 44
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky
[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky
[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky
[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky
[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky
[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky
[shortcut]
from=-3
activation=linear
#  repeat  residual module x3 end layer

#   layer 53
[convolutional]
batch_normalize=0
filters=128
size=1
stride=1
pad=1
activation=linear
# layer  55
[route]
layers = -1,-13

[batchnorm]
filters=256
[activation]
activation = leaky
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

# Downsample
# layer 58
[convolutional]
batch_normalize=1
filters=512
size=3
stride=2
pad=1
activation=leaky

# layer 59
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky
### SPP ###
[maxpool]
stride=1
size=5
[route]
layers=-2
[maxpool]
stride=1
size=9
[route]
layers=-4
[maxpool]
stride=1
size=13
[route]
layers=-1,-3,-5,-6
### End SPP ###
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

# layer ： 68
#   NeckBottle Mix Module ：
[convolutional]
batch_normalize=0
filters=256
size=1
stride=1
pad=1
activation=linear

[route]
layers = -2
[convolutional]
batch_normalize=0
filters=256
size=1
stride=1
pad=1
activation=linear
# repeat  residual module  x1
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky
# repeat  residual module x1 end
[convolutional]
batch_normalize=0
filters=256
size=1
stride=1
pad=1
activation=leaky

[route]
layers = -1,-7
[batchnorm]
filters=512
[activation]
activation = leaky
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky
# NeckBottle Mix Module end 

#layer 77
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

# fpn layer 78
[upsample]
stride=2

[route]
layers = 48,-1

#layer  81 
#   NeckBottle Mix Module ：
[convolutional]
batch_normalize=0
filters=128
size=1
stride=1
pad=1
activation=linear

[route]
layers = -2
[convolutional]
batch_normalize=0
filters=128
size=1
stride=1
pad=1
activation=linear
# repeat  residual module  x1
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky
[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky
# repeat  residual module x1 end
[convolutional]
batch_normalize=0
filters=128
size=1
stride=1
pad=1
activation=leaky

[route]
layers = -1,-7
[batchnorm]
filters=256
[activation]
activation = leaky
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky
# NeckBottle Mix Module end 

# layer  90
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[upsample]
stride=2

# layer 92
[route]
layers = -1,30

#layer  94
#   NeckBottle Mix Module ：
[convolutional]
batch_normalize=0
filters=64
size=1
stride=1
pad=1
activation=linear

[route]
layers = -2
[convolutional]
batch_normalize=0
filters=64
size=1
stride=1
pad=1
activation=linear
# repeat  residual module  x1
[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky
[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky
# repeat  residual module x1 end
[convolutional]
batch_normalize=0
filters=64
size=1
stride=1
pad=1
activation=leaky

[route]
layers = -1,-6
[batchnorm]
filters =128
[activation]
activation = leaky
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky
# NeckBottle Mix Module end 

# layer :  104
##########################
[convolutional]
size=1
stride=1
pad=1
filters=21
activation=linear

# input : 840
[yolo]
mask = 0,1,2
anchors = 6,  24,  54,   3,  10,  26,   9,  32,  12,  37,  11,  91,  24,   56,  70,  62, 249, 188
classes=2
num=9
jitter=.3
ignore_thresh = .7
truth_thresh = 1
scale_x_y = 1.2
iou_thresh=0.213
cls_normalizer=1.0
iou_normalizer=0.07
iou_loss=ciou
nms_kind=greedynms
beta_nms=0.6
# max_delta=5

# layer 106

[route]
layers = -3

[convolutional]
batch_normalize=1
filters=128
size=3
stride=2
pad=1
activation=leaky

[route]
layers = -1, 81

#layer  107
#   NeckBottle Mix Module ：
[convolutional]
batch_normalize=0
filters=128
size=1
stride=1
pad=1
activation=linear

[route]
layers = -2
[convolutional]
batch_normalize=0
filters=128
size=1
stride=1
pad=1
activation=linear
# repeat  residual module  x1
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky
[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky
# repeat  residual module x1 end
[convolutional]
batch_normalize=0
filters=128
size=1
stride=1
pad=1
activation=leaky

[route]
layers = -1,-6
[batchnorm]
filters=256
[activation]
activation = leaky
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky
# NeckBottle Mix Module end layer :  116

# layer 117
##########################
[convolutional]
size=1
stride=1
pad=1
filters=21
activation=linear

# input : 840 layer : 118
[yolo]
mask = 3,4,5
anchors = 6,  24,  54,   3,  10,  26,   9,  32,  12,  37,  11,  91,  24,   56,  70,  62, 249, 188
classes=2
num=9
jitter=.3
ignore_thresh = .7
truth_thresh = 1
scale_x_y = 1.1
iou_thresh=0.213
cls_normalizer=1.0
iou_normalizer=0.07
iou_loss=ciou
nms_kind=greedynms
beta_nms=0.6
# max_delta=5

[route]
layers = -3
[convolutional]
batch_normalize=1
filters=128
size=3
stride=2
pad=1
activation=leaky

[route]
layers = -1,68

# layer 120
#   NeckBottle Mix Module ：
[convolutional]
batch_normalize=0
filters=256
size=1
stride=1
pad=1
activation=linear

[route]
layers = -2

[convolutional]
batch_normalize=0
filters=256
size=1
stride=1
pad=1
activation=linear
# repeat  residual module  x1
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky
# repeat  residual module x1 end
[convolutional]
batch_normalize=0
filters=256
size=1
stride=1
pad=1
activation=leaky

[route]
layers = -1,-6
[batchnorm]
filters=512
[activation]
activation = leaky
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky
# NeckBottle Mix Module end layer :  116

# layer 118
##########################
[convolutional]
size=1
stride=1
pad=1
filters=21
activation=linear

# input : 840 layer : 119
[yolo]
mask =  6,7,8
anchors = 6,  24,  54,   3,  10,  26,   9,  32,  12,  37,  11,  91,  24,   56,  70,  62, 249, 188
classes=2
num=9
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=0
scale_x_y = 1.05
iou_thresh=0.213
cls_normalizer=1.0
iou_normalizer=0.07
iou_loss=ciou
nms_kind=greedynms
beta_nms=0.6
# max_delta=5
